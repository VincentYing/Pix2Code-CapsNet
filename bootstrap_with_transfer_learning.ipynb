{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras import initializers\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.optimizers import RMSprop, Adamax\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback\n",
    "from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense, GlobalAveragePooling2D\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import numpy as np\n",
    "\n",
    "# import the capsule layers stuff\n",
    "from capsulelayers import *\n",
    "\n",
    "from keras import backend as K\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_name = 'resources/eval/'\n",
    "\n",
    "# Read a file and return a string\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def load_data(data_dir):\n",
    "    text = []\n",
    "    images = []\n",
    "    # Load all the files and order them\n",
    "    all_filenames = listdir(data_dir)\n",
    "    all_filenames.sort()\n",
    "    for filename in (all_filenames):\n",
    "        if filename[-3:] == \"npz\":\n",
    "            # Load the images already prepared in arrays\n",
    "            image = np.load(data_dir+filename)\n",
    "            images.append(image['features'])\n",
    "        else:\n",
    "            # Load the boostrap tokens and rap them in a start and end tag\n",
    "            syntax = '<START> ' + load_doc(data_dir+filename) + ' <END>'\n",
    "            # Seperate all the words with a single space\n",
    "            syntax = ' '.join(syntax.split())\n",
    "            # Add a space after each comma\n",
    "            syntax = syntax.replace(',', ' ,')\n",
    "            text.append(syntax)\n",
    "    images = np.array(images, dtype=float)\n",
    "    return images, text\n",
    "\n",
    "#train_features, texts = load_data(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the function to create the vocabulary \n",
    "tokenizer = Tokenizer(filters='', split=\" \", lower=False)\n",
    "# Create the vocabulary \n",
    "tokenizer.fit_on_texts([load_doc('resources/bootstrap.vocab')])\n",
    "\n",
    "# Add one spot for the empty word in the vocabulary \n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# Map the input sentences into the vocabulary indexes\n",
    "train_sequences = tokenizer.texts_to_sequences(texts)\n",
    "# The longest set of boostrap tokens\n",
    "max_sequence = max(len(s) for s in train_sequences)\n",
    "# Specify how many tokens to have in each input sentence\n",
    "max_length = 48\n",
    "\n",
    "def preprocess_data(sequences, features):\n",
    "    X, y, image_data = list(), list(), list()\n",
    "    for img_no, seq in enumerate(sequences):\n",
    "        for i in range(1, len(seq)):\n",
    "            # Add the sentence until the current count(i) and add the current count to the output\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            # Pad all the input token sentences to max_sequence\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_sequence)[0]\n",
    "            # Turn the output into one-hot encoding\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            # Add the corresponding image to the boostrap token file\n",
    "            image_data.append(features[img_no])\n",
    "            # Cap the input sentence to 48 tokens and add it\n",
    "            X.append(in_seq[-48:])\n",
    "            y.append(out_seq)\n",
    "    return np.array(X), np.array(y), np.array(image_data)\n",
    "\n",
    "#X, y, image_data = preprocess_data(train_sequences, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, y, image_data\n",
    "# X.shape = (*,48)\n",
    "# y.shape = (*,18)\n",
    "# image_data.shape = (*,256,256,3)\n",
    "# [image_data, X], y\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dir_name, list_IDs, tokenizer, batch_size=1, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dir_name = dir_name\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = range(len(list_IDs))\n",
    "        self.tokenizer = tokenizer\n",
    "        #self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __load_data_batch(self, data_dir, list_IDs_temp):\n",
    "        text = []\n",
    "        images = []\n",
    "        # Load files in batch\n",
    "        for filename in (list_IDs_temp):\n",
    "            image_file = filename + \".npz\"\n",
    "            # Load the images already prepared in arrays\n",
    "            image = np.load(data_dir+image_file)\n",
    "            images.append(image['features'])\n",
    "\n",
    "            text_file = filename + \".gui\"\n",
    "            # Load the boostrap tokens and rap them in a start and end tag\n",
    "            syntax = '<START> ' + load_doc(data_dir+text_file) + ' <END>'\n",
    "            # Seperate all the words with a single space\n",
    "            syntax = ' '.join(syntax.split())\n",
    "            # Add a space after each comma\n",
    "            syntax = syntax.replace(',', ' ,')\n",
    "            text.append(syntax)\n",
    "        images = np.array(images, dtype=float)\n",
    "        return images, text\n",
    "\n",
    "    def __preprocess_data(self, sequences, features):\n",
    "        X, y, image_data = list(), list(), list()\n",
    "        for img_no, seq in enumerate(sequences):\n",
    "            for i in range(1, len(seq)):\n",
    "                # Add the sentence until the current count(i) and add the current count to the output\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                # Pad all the input token sentences to max_sequence\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_sequence)[0]\n",
    "                # Turn the output into one-hot encoding\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                # Add the corresponding image to the boostrap token file\n",
    "                image_data.append(features[img_no])\n",
    "                # Cap the input sentence to 48 tokens and add it\n",
    "                X.append(in_seq[-48:])\n",
    "                y.append(out_seq)\n",
    "        return np.array(X), np.array(y), np.array(image_data)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Generate data\n",
    "        train_features, texts = self.__load_data_batch(dir_name, list_IDs_temp)\n",
    "        \n",
    "        # Map the input sentences into the vocabulary indexes\n",
    "        train_sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "        X, y, image_data = self.__preprocess_data(train_sequences, train_features)\n",
    "\n",
    "        return [image_data, X], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 10,\n",
    "          'shuffle': True,\n",
    "          'tokenizer': tokenizer}\n",
    "\n",
    "# Datasets\n",
    "# Gather list of files, store in partition\n",
    "all_filenames = listdir(dir_name)\n",
    "all_filenames.sort()\n",
    "filenames = []\n",
    "for filename in (all_filenames):\n",
    "    if filename[-3:] == \"npz\":\n",
    "        filenames.append(filename[:-4])\n",
    "\n",
    "num_files = len(filenames)\n",
    "train_size = int(num_files * 0.9)\n",
    "val_size = num_files - train_size\n",
    "train_idx = np.random.randint(num_files, size=train_size)\n",
    "val_idx = np.random.randint(num_files, size=val_size)\n",
    "train = [filenames[i] for i in train_idx]\n",
    "val = [filenames[i] for i in val_idx]\n",
    "partition = {}\n",
    "partition['train'] = train\n",
    "partition['validation'] = val\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(dir_name, partition['train'], **params)\n",
    "validation_generator = DataGenerator(dir_name, partition['validation'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mobile_net = MobileNet(include_top=False, input_shape = (256, 256, 3), input_tensor=x)\n",
    "# ^^^ this doesn't work because the input shape has to match...we can try to downsample the original image first?\n",
    "# will work on this later (Moose)\n",
    "\n",
    "\n",
    "# can also do fine-tuning if you identify which layer you want to freeze from\n",
    "# see: https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2\n",
    "def get_basemodel_frozen():\n",
    "    base_model = InceptionResNetV2(include_top=False, input_shape = (256, 256, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    return base_model\n",
    "\n",
    "\n",
    "resnet_frozen_model = get_basemodel_frozen();\n",
    "\n",
    "def transfer_learning_network(x, base_model):\n",
    "    base_model_output = base_model(x)\n",
    "    pooled_last_layer = GlobalAveragePooling2D()(base_model_output) # converts shape MxNxC => 1xC\n",
    "    # put a fully connected layer on top of the base_model output (should probably increase the size of FC layer)\n",
    "    # or use multiple FC layers...or use dropout layers etc...\n",
    "    dense_output = Dense(1024)(pooled_last_layer)\n",
    "    \n",
    "    # should probably move this out of this function to make it cleaner\n",
    "    repeated_features = RepeatVector(max_length)(dense_output)\n",
    "    return repeated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the encoder\n",
    "visual_input = Input(shape=(256, 256, 3,))\n",
    "encoded_image = transfer_learning_network(visual_input, resnet_frozen_model)\n",
    "\n",
    "language_input = Input(shape=(max_length,))\n",
    "language_model = Embedding(vocab_size, 50, input_length=max_length, mask_zero=True)(language_input)\n",
    "language_model = LSTM(128, return_sequences=True)(language_model)\n",
    "language_model = LSTM(128, return_sequences=True)(language_model)\n",
    "\n",
    "#Create the decoder\n",
    "decoder = concatenate([encoded_image, language_model])\n",
    "decoder = LSTM(512, return_sequences=True)(decoder)\n",
    "decoder = LSTM(512, return_sequences=False)(decoder)\n",
    "decoder = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=[visual_input, language_input], outputs=decoder)\n",
    "optimizer = RMSprop(lr=0.0001, clipvalue=1.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model-transfer.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "# generate a description for an image\n",
    "def generate_desc(loaded_model, tokenizer, photo, max_length):\n",
    "    photo = np.array([photo])\n",
    "    # seed the generation process\n",
    "    in_text = '<START> '\n",
    "    # iterate over the whole length of the sequence\n",
    "    #print('\\nPrediction---->\\n\\n<START> ', end='')\n",
    "    for i in range(150):\n",
    "        # integer encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad input\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        # predict next word\n",
    "        yhat = loaded_model.predict([photo, sequence], verbose=0)\n",
    "        # convert probability to integer\n",
    "        yhat = np.argmax(yhat)\n",
    "        # map integer to word\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        # stop if we cannot map the word\n",
    "        if word is None:\n",
    "            break\n",
    "        # append as input for generating the next word\n",
    "        in_text += word + ' '\n",
    "        # stop if we predict the end of the sequence\n",
    "        #print(word + ' ', end='')\n",
    "        if word == '<END>':\n",
    "            break\n",
    "    return in_text\n",
    "\n",
    "class BleuCallback(Callback):\n",
    "    max_length = 48\n",
    "    \n",
    "    def __init__(self, texts, train_features, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.train_features = train_features\n",
    "        self.tokenizer = tokenizer\n",
    "        return\n",
    "        \n",
    "    # evaluate the skill of the model\n",
    "    def evaluate_model(self, model, texts, photos, tokenizer, max_length):\n",
    "    #def evaluate_model(model, texts, photos, tokenizer, max_length):\n",
    "        actual, predicted = list(), list()\n",
    "        # step over the whole set\n",
    "        for i in range(len(texts)):\n",
    "            yhat = generate_desc(model, tokenizer, photos[i], max_length)\n",
    "            # store actual and predicted\n",
    "            #print('\\n\\nReal---->\\n\\n' + texts[i])\n",
    "            actual.append([texts[i].split()])\n",
    "            predicted.append(yhat.split())\n",
    "        # calculate BLEU score\n",
    "        bleu = corpus_bleu(actual, predicted)\n",
    "        print('\\nBleu Score: {}\\n'.format(bleu))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.evaluate_model(self.model, self.texts, self.train_features, self.tokenizer, max_length)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the model for every 2nd epoch\n",
    "filepath=\"org-weights-epoch-{epoch:04d}--val_loss-{val_loss:.4f}--loss-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=True, period=1)\n",
    "# Tensorboard\n",
    "board = TensorBoard(log_dir='./logs', histogram_freq=10, batch_size=10, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "# Bleu Score\n",
    "bleu = BleuCallback(texts, train_features, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#callbacks_list = [checkpoint, board, bleu]\n",
    "#history = model.fit([image_data, X], y, batch_size=10, shuffle=False, validation_split=0.1, callbacks=callbacks_list, verbose=1, epochs=2)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator, \n",
    "                    callbacks=callbacks_list,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training loss', 'validation loss'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
